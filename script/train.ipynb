{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6966dd42",
   "metadata": {},
   "source": [
    "# Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adebcfa9-c80e-453e-b6f9-257197c5f264",
   "metadata": {},
   "outputs": [],
   "source": [
    "#installing dependencies\n",
    "!pip install -U --pre triton\n",
    "!pip install -U xformers\n",
    "!pip install accelerate transformers datasets\n",
    "!pip install bitsandbytes\n",
    "!pip install diffusers\n",
    "!pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113\n",
    "!pip install peft\n",
    "!pip install tensorboard\n",
    "!pip install safetensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d14d9cb-b381-45bf-992a-8ef47d01b901",
   "metadata": {},
   "outputs": [],
   "source": [
    "#installing the latest version of diffusers to mitigate errors\n",
    "!pip uninstall -y diffusers\n",
    "!pip install git+https://github.com/huggingface/diffusers.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b158e53-6e92-447a-a4d7-9a0fcfcb43cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#upgrading the following libraries to mitigate errors\n",
    "!pip install --upgrade transformers accelerate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d4e5d4-aec2-4c7c-be6c-c6564ae3b8b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f429f4b87b440ec8c5492e8399e5c4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#logging into huggingface hub\n",
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb03f00",
   "metadata": {},
   "source": [
    "# Unzip Image Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55924dd0-becc-4d71-95fd-6698fc23e396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzip tool\n",
    "!apt-get update\n",
    "!apt-get install -y unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abee4846-0641-45ed-bcd7-3c6eb739e32b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /workspace/pytorch_lora_weights.safetensors.zip\n",
      "  inflating: /workspace/pytorch_lora_weights.safetensors  \n",
      "  inflating: /workspace/__MACOSX/._pytorch_lora_weights.safetensors  \n"
     ]
    }
   ],
   "source": [
    "# unzip image dataset\n",
    "# wait till the upload is complete\n",
    "!unzip /workspace/pytorch_lora_weights.safetensors.zip -d /workspace/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b9ac74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# terminate  \n",
    "!ps aux | grep accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7889718-7a5a-4207-9eba-e3038c776cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove saved checkpoint directory\n",
    "!rm -rf /workspace/kanji-diffusion-v1-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e307b0-4ad0-45bf-9c1c-d4adcc39b3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the main training script\n",
    "# this pass the parameter to train_text_image_lora.py \n",
    "!accelerate launch --mixed_precision=\"no\" --num_processes=1 --num_machines=1 --dynamo_backend=\"no\" train_text_to_image_lora.py \\\n",
    "    --pretrained_model_name_or_path=\"CompVis/stable-diffusion-v1-4\" \\\n",
    "    --train_data_dir=\"/workspace/traindata\" \\\n",
    "    --image_column=\"image\" \\\n",
    "    --caption_column=\"text\" \\\n",
    "    --resolution=128 \\\n",
    "    --lora_rank=32 \\\n",
    "    --train_batch_size=1 \\\n",
    "    --num_train_epochs=8 \\\n",
    "    --checkpointing_step=2560 \\\n",
    "    --validation_steps=2560 \\\n",
    "    --learning_rate= \\\n",
    "    --lr_scheduler=\"cosine\" \\\n",
    "    --lr_warmup_steps=0 \\\n",
    "    --seed=42 \\\n",
    "    --output_dir=\"kanji-diffusion-v1-4\" \\\n",
    "    --report_to=\"tensorboard\" \\\n",
    "    --logging_dir=\"logs\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002640f1",
   "metadata": {},
   "source": [
    "# Test Inference Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b272db-aeb2-4973-aa27-1056995fa733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baa8e87ebdf740f4bd64a48d3efa3d1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Loading the pre-trained Stable Diffusion model and moving it to GPU for efficient processing.\n",
    "from diffusers import StableDiffusionPipeline\n",
    "import torch\n",
    "\n",
    "model_id = \"CompVis/stable-diffusion-v1-4\"\n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)\n",
    "pipe = pipe.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5ed2e3-83ac-4571-be7a-1db3690f279a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and apply LoRA weights\n",
    "lora_model_path = \"/workspace/pytorch_lora_weights.safetensors\"\n",
    "pipe.unet.load_attn_procs(lora_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f25b421-109e-45bc-b7f4-7850368fa7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines a function to generate and display images based on text prompts\n",
    "def generate_image(prompt, num_images=1):\n",
    "    images = pipe(prompt, num_images_per_prompt=num_images,height=128,width=128).images\n",
    "    for i, image in enumerate(images):\n",
    "        display(image)\n",
    "        image.save(f\"generated_image_{i}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e067e9-9558-4694-87d7-1bd859d43932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mount sample prompts\n",
    "sample_prompts = [\n",
    "    \"dog\",\n",
    "    \"cat\",\n",
    "    \"car\",\n",
    "    \"school\",\n",
    "    \"pizza\",\n",
    "    \"train\",\n",
    "    \"ball\",\n",
    "    \"star\",\n",
    "    \"milk\",\n",
    "    \"home\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9357632f-9a47-442e-84cb-7e2fc170248d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Folder to save images\n",
    "out_dir = \"output-american-culture\"\n",
    "os.makedirs(\n",
    "    out_dir, exist_ok=True)\n",
    "\n",
    "# Loop over your prompts\n",
    "for prompt in cultural_simple:\n",
    "    images = pipe(prompt, num_images_per_prompt=20, height=128, width=128).images\n",
    "    for i, image in enumerate(images, start=1):\n",
    "        filename = f\"{prompt.replace(' ', '_')}{i}.png\"\n",
    "        save_path = os.path.join(out_dir, filename)\n",
    "        image.save(save_path)\n",
    "        display(image)  # optional, shows in notebook\n",
    "        print(f\"✅ Saved {save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
